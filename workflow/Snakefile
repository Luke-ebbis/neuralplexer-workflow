## NeuralPlexer workflow for investigating protein-ligand binding.
## 
## A workflow to predict the interaction between proteins and Ligands using
## NeuralPlexer by Qiao et al. Right now, the usage of PDB files with SIF files
## as ligands is supported.
## 
## Workflow made by Sibbe Bakker

import json
from pathlib import Path

DATA_DIR = "data/"
OUTDIR = "results/data/"

JOBS=[name.replace(".json", "") 
  for name in os.listdir(DATA_DIR) if name.endswith("json")]

def parse_json(file_path: str) -> Dict:
    with open(file_path, 'r') as file:
        data = json.load(file)
        return data

        
def get_structures(path, outdir, type="prot_all.pdb", name_only=True):
  json_files = [f"{DATA_DIR}/{name}"
   for name in os.listdir(path) if name.endswith("json")]
  structures = []
  for json in json_files:
    jobname = Path(json).stem
    data = parse_json(json)
    for job in data:
      name = job["name"]
      if name_only:
        file=f"{name}{type}"
      else:
        file = f"{OUTDIR}{jobname}/{name}/{type}"
      structures.append(file)
  return structures


STRUCTURES = get_structures(DATA_DIR, OUTDIR)

## output:
##    A directory with SIF files, holding the different possible locations of
##    the predicted ligands, and the pdb file with the receptor structure.
##
rule all:
  input:
    expand("{out}{jobname}",
        jobname=JOBS, out=OUTDIR),
    expand("results/analysis/sasa/{name}.pdb.sasa.png", 
        name=[Path(f).stem for f in STRUCTURES]),
    expand("results/analysis/sasa/{name}.pdb.sasa.csv", 
        name=[Path(f).stem for f in STRUCTURES])

wildcard_constraints:
    jobname="\w+" # equivalent to {sample,\w+} - limits to alphabet letters

## Rules
## =====
## 


## install_sdf:
##    Install the scidata flow tool using cargo.
## 
rule install_sdf:
  output:
    touch("results/checkpoint/sdf_install")
  shell:
    """
    cargo install scidataflow
    """

## calculate_accesability_profile:
##    Calculate the accessability profile of the calculated structures.
## 
rule calculate_accessability_profile:
  conda:
    "envs/mol.yml"
  input:
    get_structures(DATA_DIR, OUTDIR, name_only=False)
  output:
    "results/analysis/sasa/{name}.pdb.sasa.png",
    "results/analysis/sasa/{name}.pdb.sasa.csv",
  script:
    "scripts/mol/surface.py"


## install_neural_plexer_apptainer:
##    Installs the NeuralPlexer tool from the docker image as an Apptainer.
##    It uses the docker image as listed on 
##    [drailab docker hub](https://hub.docker.com/r/drailab/neuralplexer).
##
rule install_neural_plexer_apptainer:
  """Build the NeuralPlexer container

  Documentation:
    See [docs](https://apptainer.org/docs/user/latest/build_a_container.html)
    for more information.
  """
  output: "results/dependencies/neuralplexer/neuralplexer.sif"
  shell:
    """
    # the Docker command that would've done this is
    # docker pull drailab/neuralplexer
    apptainer build {output} docker://drailab/neuralplexer
    """

## download_neuralplexer_checkpoint_data:
##    Will download 8.3 Gb of NeuralPlexer model data from Zenodo, containing 
##    the model weights and testing data.
##
rule download_neuralplexer_checkpoint_data:
  output: "results/downloads/NeuralPlexerModelData.zip"
  shell:
    """
    wget -O {output} https://zenodo.org/records/10373581/files/neuralplexermodels_downstream_datasets_predictions.zip?download=1
    """

## Unzip the downloaded neuralplexer data:
##    The dataset contains the weights and the test data. In total 24 GB. Of
##    which the weights (data/neuralplexermodels_downstream_datasets_predictions
##    /models/complex_structure_prediction.ckp) make up 2.8 Gb.
##
rule unzip_neuralplexer_checkpoint_data:
  input: "results/downloads/NeuralPlexerModelData.zip"
  output: directory("results/dependencies/neuralplexer/data")
  shell:
    """
    mkdir {output}
    unzip {input} -d {output}
    """

## run_neural_plexer:
##    Run the neuralplexer tool on a job directory, with a pdb file as the 
##    receptor and a SIF file as the ligand. Multiple SIF files are supported.
##
rule run_neural_plexer:
  """neuralplexer rule

  note -- for now only sdf files are supported.
  """
  input:
    image="resources/images/np-updated.sif",
    checkpoint="results/dependencies/neuralplexer/data/neuralplexermodels_downstream_datasets_predictions/models/complex_structure_prediction.ckpt",
    jobs="data/{jobname}.json"
  output:
    directory("results/data/{jobname}/")
  shell:
    """
    python workflow/scripts/neuralplexer.py {input.image} \
      {input.checkpoint} {input.jobs} {output}
    echo "Job completed!\n {output}"
    cp {input.jobs} {output}
    """


## help:
##    Show the help.
##
rule help:
  input: "workflow/Snakefile"
  shell:
      "sed -n 's/^##//p' {input}"

## clean:                     
##    Clean all outputs from the results/data folder. Ignores the downloaded
##    NeuralPlexer dependencies.  
##
rule clean:
  shell:
      "rm -rf results/data"

## build_overview:            
##    Print the directed acyclic graph.
##
rule build_overview:
  output:
    "results/method.{fileformat}"
  shell:
    """
    snakemake -c 1 --forceall --dag | dot -T{wildcards.fileformat} > {output}
    """
